---
layout: about
title: about
permalink: /
subtitle: Trying to figure out where (and where not ‼️) to use AI in the design of aerospace systems.

profile:
  align: right
  image: jk_pic_3-4.jpg
  image_circular: true # crops the image to make it circular
  more_info: >
    <p>Georgia Tech<\p>


selected_papers: false # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page

announcements:
  enabled: false # includes alist of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: true
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

Engineering is about making useful things. Sometimes these things are new (a new civil aircraft design) and sometimes these things are *really* new (a logistics system to get crew and cargo between Earth, Mars, and the Moon). The distinction there isn't really between aero and astro, although aero systems have an accessibility advantage and a mild head start.

Systems engineering is about studying the way we achieve these useful things.
This can be about designing systems, but it can also be about understanding the tradeoffs that are made in realizing them.
There's a lot of communication that goes into the coordination of a team around the thing they're building. This may include decisions about what shared languages and shared views of that system they use.
In many ways, doing engineering requires becoming very familiar with a set of representations of a vehicle, system, or problem space and having deep insight into how changing the settings of a representational element (design variable, etc.) implicates the system, its performance, and our ability to design it.

Learning representations of various processes as complicated as language generation from large datasets has been surprisingly effective. But in some ways the results can be unsatisfying. If the representations are embedded in an extremely high-dimensional neural representation, how do we learn and grow from this knowledge as humans?

This observation is fairly basic, but I find it to be a tantalizing problem. AI usage is sweeping across many industries. Keeping track of the complexity of an engineered system was already a problem (think F-35 development timelines) before we started introducing [probabilistic teammates](https://engtechnica.com/p-1-ai-comes-out-of-stealth-to-build-agi-for-engineering-design/).

So right now I'm thinking about:
**How do we build tools which augment our systems intelligence?**

I'm a graduate student in the Aerospace Engineering PhD Program at Georgia Tech. Before that I got my SM in AE at Georgia Tech and my SB in AeroAstro at MIT.